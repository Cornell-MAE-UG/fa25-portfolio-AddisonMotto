---
layout: project
title: MAE 4300
description: Just a spaceship that I designed
technologies: [SolidWorks, Machining]
image: /assets/images/airplane.jpg
---

## Disaster Overview
The Boeing 737 MAX disasters refer to two fatal commercial aviation crashes involving the 737 MAX aircraft: Lion Air Flight 610 in October 2018, which killed all 189 people on board, and Ethiopian Airlines Flight 302 in March 2019, which resulted in 157 fatalities. Together, these crashes claimed 346 lives and led to the worldwide grounding of the 737 MAX fleet. Investigations revealed that both accidents were linked to Boeing’s Maneuvering Characteristics Augmentation System (MCAS), an automated flight-control feature that repeatedly pushed the aircraft’s nose downward in response to faulty data from a single angle-of-attack sensor. Critically, MCAS was introduced as part of a redesign of the 737 to accommodate larger engines, but its existence and behavior were not clearly disclosed to pilots. This lack of transparency was driven in part by Boeing’s desire to market the 737 MAX as requiring minimal additional pilot training, avoiding costly simulator sessions for airlines and maintaining competitiveness with Airbus. As a result, flight crews were left unprepared to recognize and respond to the system’s failures, contributing directly to the catastrophic outcomes.

## Ethical Questions Raised by the Boeing 737 MAX Disasters

1. **To what extent should Boeing have disclosed MCAS changes in pilot manuals and training materials?**  
   The decision to minimize or omit information about MCAS reflects an effort to downplay a significant system modification for financial and competitive reasons. This raises concerns about whether passenger safety was deprioritized in favor of reducing training costs and maintaining market advantage.

2. **Did Boeing’s relationship with FAA designees undermine the independence of the certification process?**  
   Boeing’s reliance on internal employees authorized to act on behalf of the FAA allowed critical safety decisions to remain largely within the company. This structure calls into question the credibility of regulatory oversight and weakens public trust in the certification system.

3. **Should the entire 737 MAX fleet have been grounded following the first fatal crash?**  
   Boeing’s choice not to immediately ground all 737 MAX aircraft after the Lion Air crash suggests a failure to fully acknowledge systemic risk. Continuing operations despite unresolved safety concerns exposed additional passengers and flight crews to potential danger.

4. **How could Boeing have better incorporated and responded to internal engineering safety concerns?**  
   Companies whose engineering decisions affect millions of lives must implement formal processes for documenting, reviewing, and addressing safety concerns. Anonymous reporting mechanisms may also be necessary to protect lower-level engineers who fear retaliation for speaking up.

5. **What role should engineers play in management decisions within safety-critical industries?**  
   Marginalizing engineers in leadership positions can result in decisions driven primarily by business priorities rather than technical risk. Ethical decision-making in aviation requires management structures that are informed by engineering expertise and explicitly trained to prioritize safety.

## Summary of Key Facts and Actors

The Boeing 737 MAX disasters resulted from a combination of technical design decisions, individual actions, and organizational pressures that interacted in harmful ways. At the system level, the Maneuvering Characteristics Augmentation System (MCAS) relied on input from a single angle-of-attack sensor, making it vulnerable to erroneous data. When activated, MCAS could repeatedly command nose-down inputs without clear limits or sufficient pilot awareness. These design choices were closely tied to Boeing’s effort to modify the existing 737 platform to accommodate larger engines while avoiding the costs associated with a new aircraft design and additional pilot training.

Individual decisions also played a significant role. FAA officials delegated substantial portions of the certification process to Boeing employees, reducing independent oversight. Test pilots and engineers raised concerns about MCAS behavior and documentation, but those concerns were not fully addressed or communicated to flight crews. In particular, MCAS was not clearly described in pilot manuals, leaving pilots unprepared to recognize and respond to its failures during flight.

At the organizational level, Boeing’s corporate culture and incentive structure prioritized speed to market and competition with Airbus over conservative safety practices. After the first crash, the company did not immediately ground the 737 MAX fleet, allowing continued operation despite unresolved risks. Financial pressures, regulatory delegation, and internal management decisions collectively weakened safety accountability and contributed to the conditions that led to the second fatal crash.


## Reasonable Assumptions and Missing Information

Several key facts surrounding the development, certification, and response to MCAS remain unclear, requiring reasonable assumptions to understand how the failures occurred. It is not fully known what FAA technical staff were aware of regarding MCAS’s reliance on a single angle-of-attack sensor, nor why that design choice was approved despite its obvious risk. There is also limited transparency into the extent of Boeing’s internal knowledge gaps, including what engineers communicated to management about MCAS behavior and how simulator and flight-test data were evaluated during certification.

Given the available evidence, it is reasonable to assume that MCAS was initially believed to activate only under rare, high-speed flight conditions and was therefore viewed as low risk. This assumption likely contributed to decisions not to include redundancy, limit system authority, or require additional pilot training. It is also reasonable to infer that some safety concerns were either not formally documented or were not escalated through management due to time pressure and cost constraints.

Organizational and financial pressures further shaped these outcomes. Significant cost incentives existed to avoid simulator training, as doing so would have increased airline expenses and reduced the competitiveness of the 737 MAX. Engineers were likely encouraged, implicitly or explicitly, to frame issues in ways that minimized disruption to schedules and certification timelines. Additional training requirements, more extensive simulator testing, or alternative technical designs appear to have been considered but ultimately not pursued, contributing to the systemic failure that followed.

## Refining the Ethical Issues

With a clearer understanding of the technical facts, assumptions, and stakeholder impacts, the ethical issues surrounding the Boeing 737 MAX can be more precisely defined. Rather than asking broad questions about transparency or responsibility, the focus shifts to specific decisions and actors. For example, the ethical issue is not simply whether Boeing should have been more transparent, but whether Boeing should have disclosed detailed MCAS functionality to pilots and airlines prior to certification, given the system’s authority and reliance on a single sensor.

A more refined ethical framing also requires identifying who held decision-making authority at key points. Senior Boeing engineers, management, and FAA designees all played roles in approving MCAS design choices and certification pathways. Ethical responsibility therefore lies not with a vague system failure, but with specific individuals and organizational structures that allowed known risks to persist. Questions such as whether engineers should have refused to approve MCAS under single-sensor dependency directly address accountability within the engineering hierarchy.

These issues also reflect broader systemic forces, including regulatory delegation, competitive pressure from Airbus, and the global implications of commercial aviation safety. Ethical analysis must consider how engineers balanced loyalty to their employer against their obligation to protect public safety, especially in an environment where certification authority was partially delegated to the manufacturer. Applying professional engineering ethics principles highlights conflicts between business incentives and the foundational duty to hold public safety paramount, a duty that should take precedence in safety-critical systems like commercial aircraft.

## Resolving the Ethical Issues

A central ethical question in the Boeing 737 MAX case is whether certification engineers should have approved the MCAS system despite its reliance on a single angle-of-attack sensor and the lack of pilot notification. Based on the technical facts, reasonable assumptions, and established engineering ethics principles, the ethically correct action would have been to refuse certification until the system was redesigned or adequately disclosed.

MCAS depended on input from a single AOA sensor, creating a clear single point of failure in a safety-critical flight control system. Pilots were not informed of MCAS’s existence or behavior, limiting their ability to diagnose or override erroneous nose-down commands. Boeing was aware that sensor failures could trigger repeated MCAS activations, and alternative designs incorporating sensor redundancy were technically feasible but not implemented due to cost and schedule concerns.

It is reasonable to assume that certification engineers possessed sufficient technical expertise to recognize the risks associated with single-sensor dependency. Stakeholders such as airlines, pilots, and regulators reasonably assumed that Boeing followed established aerospace safety norms, including redundancy in flight control systems. Engineers also had access to internal reporting mechanisms to raise concerns prior to final certification.

Under **ASME Canon 1 (Hold Paramount the Safety of the Public)**, approving a system with known single-point-of-failure characteristics that could endanger passengers is ethically unacceptable. **Canon 2 (Professional Competence)** is violated when engineers endorse designs that fall below established safety standards for aerospace systems. Additionally, **Canon 7 (Truthful Communication)** is implicated, as certifying MCAS without fully disclosing its design limitations and failure modes misrepresented the system’s safety to pilots and regulators.

Refusing MCAS certification would likely have delayed the aircraft’s entry into service but could have prevented loss of life and preserved trust in the aviation safety system. While economic and competitive pressures were significant, ethical engineering practice requires that public safety take precedence over cost, schedule, and market competition. In the long term, adherence to these principles would have better protected both passengers and Boeing itself from the severe consequences that ultimately followed.
